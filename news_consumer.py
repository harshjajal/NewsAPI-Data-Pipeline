# -*- coding: utf-8 -*-
"""news_consumer_new.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y8JUDLXkjf7vqNsoLtv6S_gjMW9zZ__C
"""

from kafka import KafkaConsumer
import json
import csv
import os

# Kafka configuration
bootstrap_servers = 'localhost:9092'
consumer_topic = 'my-news'

# Kafka consumer initialization
consumer = KafkaConsumer(consumer_topic,
                         bootstrap_servers=bootstrap_servers,
                         value_deserializer=lambda x: json.loads(x.decode('utf-8')))

# Define the directory to save the CSV file
output_directory = '/home/fedelio420/'

# Create the output directory if it doesn't exist
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

# Define the CSV file path
csv_file_path = os.path.join(output_directory, 'news_data.csv')

# Open a CSV file for writing
csv_file = open(csv_file_path, 'w', newline='')
csv_writer = csv.writer(csv_file)

# Write CSV header
csv_writer.writerow(['Title', 'Description', 'Source', 'PublishedAt', 'URL'])

# Consume messages and save as CSV rows
for message in consumer:
    article = message.value
    cleaned_data = [
        article['title'],
        article['description'],
        article['source'],
        article['publishedAt'],
        article['url']
    ]
    # Print the data
    print("Title:", cleaned_data[0])
    print("Description:", cleaned_data[1])
    print("Source:", cleaned_data[2])
    print("PublishedAt:", cleaned_data[3])
    print("URL:", cleaned_data[4])
    print("=" * 50)

    # Write data to CSV file
    csv_writer.writerow(cleaned_data)

# Close the CSV file and consumer
csv_file.close()
consumer.close()